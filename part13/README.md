# PART 13

course content: https://fullstackopen.com/en/part13

project github: https://github.com/linhaishe/part13-fullstack

1. dockeréƒ¨ç½²Postgres Imagesæ•°æ®åº“
2. ä¸€ä¸ªåç«¯æœåŠ¡bloglist-backend
3. sequelizeæ“ä½œPostgresæ•°æ®åº“

# SQL Base

## 1. SELECT / FROM

```sql
# Select query for all columns
SELECT * 
FROM mytable;

# Select query for a specific columns
SELECT column, another_column, â€¦
FROM mytable;
```

## 2. WHERE / conditions

```sql
SELECT column, another_column, â€¦
FROM mytable
WHERE condition
    AND/OR another_condition
    AND/OR â€¦;

SELECT * FROM movies WHERE id = 6;

SELECT title, year
FROM movies
ORDER BY year ASC
LIMIT 5;
```

| Operator            | Condition                                            | SQL Example                           |
| ------------------- | ---------------------------------------------------- | ------------------------------------- |
| =, !=, <, <=, >, >= | Standard numerical operators                         | col_name **!=** 4                     |
| BETWEEN â€¦ AND â€¦     | Number is within range of two values (inclusive)     | col_name **BETWEEN** 1.5 **AND** 10.5 |
| NOT BETWEEN â€¦ AND â€¦ | Number is not within range of two values (inclusive) | col_name **NOT BETWEEN** 1 **AND** 10 |
| IN (â€¦)              | Number exists in a list                              | col_name **IN** (2, 4, 6)             |
| NOT IN (â€¦)          | Number does not exist in a list                      | col_name **NOT IN** (1, 3, 5)         |

| Operator   | Condition                                                    | Example                                                      |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| =          | Case sensitive exact string comparison (*notice the single equals*) | col_name **=** "abc"                                         |
| != or <>   | Case sensitive exact string inequality comparison            | col_name **!=** "abcd"                                       |
| LIKE       | Case insensitive exact string comparison                     | col_name **LIKE** "ABC"                                      |
| NOT LIKE   | Case insensitive exact string inequality comparison          | col_name **NOT LIKE** "ABCD"                                 |
| %          | Used anywhere in a string to match a sequence of zero or more characters (only with LIKE or NOT LIKE) | col_name **LIKE** "%AT%" (matches "AT", "ATTIC", "CAT" or even "BATS") |
| _          | Used anywhere in a string to match a single character (only with LIKE or NOT LIKE) | col_name **LIKE** "AN_" (matches "AND", but not "AN")        |
| IN (â€¦)     | String exists in a list                                      | col_name **IN** ("A", "B", "C")                              |
| NOT IN (â€¦) | String does not exist in a list                              | col_name **NOT IN** ("D", "E", "F")                          |

## 3. conditions / DISTINCT

```sql
# Select query with unique results
# DISTINCT keyword will blindly remove duplicate rows
SELECT DISTINCT column, another_column, â€¦
FROM mytable
WHERE condition(s);
```

```sql
# Select query with ordered results
SELECT column, another_column, â€¦
FROM mytable
WHERE condition(s)
ORDER BY column ASC/DESC;
```

```sql
# Select query with limited rows
SELECT column, another_column, â€¦
FROM mytable
WHERE condition(s)
ORDER BY column ASC/DESC
LIMIT num_limit OFFSET num_offset;
# and the optional OFFSET will specify where to begin counting the number rows from
# OFFSET åäº”ä¸ª
```

## 4. ORDER BY / LIMIT / OFFSET

 the `INNER JOIN` we used last lesson might not be sufficient because the resulting table only contains data that belongs in both of the tables.

```sql
# Select query with INNER JOIN on multiple tables
SELECT column, another_table_column, â€¦
FROM mytable
INNER JOIN another_table 
    ON mytable.id = another_table.id
WHERE condition(s)
ORDER BY column, â€¦ ASC/DESC
LIMIT num_limit OFFSET num_offset;
```

## 5. OUTER JOINS

If the two tables have asymmetric data, which can easily happen when data is entered in different stages, then we would have to use a `LEFT JOIN`, `RIGHT JOIN` or `FULL JOIN` instead to ensure that the data you need is not left out of the results.

**LEFT/RIGHT/FULL JOIN**

```sql
SELECT column, another_column, â€¦
FROM mytable
LEFT/RIGHT/FULL JOIN another_table 
    ON mytable.id = another_table.matching_id
WHERE condition(s)
ORDER BY column, â€¦ ASC/DESC
LIMIT num_limit OFFSET num_offset;
```

 joining table A to table B

- a `LEFT JOIN` simply includes rows from A regardless of whether a matching row is found in B
- The `RIGHT JOIN` is the same, but reversed, keeping rows in B regardless of whether a match is found in A.
- Finally, a `FULL JOIN` simply means that rows from both tables are kept, regardless of whether a matching row exists in the other table.

```sql
# no diff
SELECT DISTINCT building_name
FROM buildings
JOIN employees
ON buildings.building_name = employees.building;

# with diff and all
SELECT DISTINCT role, building_name	
FROM buildings
LEFT JOIN employees
ON buildings.building_name = employees.building
```

## 6. **NULLs**

```sql
# Select query with constraints on NULL values
SELECT column, another_column, â€¦
FROM mytable
WHERE column IS/IS NOT NULL
AND/OR another_condition
AND/OR â€¦;
```

```sql
SELECT buildings.building_name
FROM buildings
LEFT JOIN employees
ON buildings.building_name = employees.building
WHERE employees.building IS NULL;
```

## 7. **AS**

 a descriptive *alias* using the `AS` keyword.æ–°å¢ä¸€åˆ—

```sql
# Example query with expressions 
SELECT particle_speed / 2.0 AS half_particle_speed
FROM physics_data
WHERE ABS(particle_position) * 10.0 > 500;

# Select query with expression aliases
SELECT col_expression AS expr_description, â€¦
FROM mytable;

# Example query with both column and table name aliases
SELECT column AS better_column_name, â€¦
FROM a_long_widgets_table_name AS mywidgets
INNER JOIN widget_sales
ON mywidgets.id = widget_sales.widget_id;
```

```sql
# List all movies and their combined sales in millions of dollars 
SELECT 
    movies.title,
    (boxoffice.domestic_sales + boxoffice.international_sales)/1000000 AS total_sales_million
FROM movies
INNER JOIN boxoffice
ON movies.id = boxoffice.movie_id
ORDER BY total_sales_million DESC;
```

![image-20251029180435063](https://s2.loli.net/2025/11/11/3zCL8TROnJadiuW.png)

```sql
SELECT 
    movies.title,
    boxoffice.rating,
    ROUND(boxoffice.rating / 10 * 100, 0) AS rating_percent
FROM movies
INNER JOIN boxoffice
ON movies.id = boxoffice.movie_id
ORDER BY rating_percent DESC;

```

## 8. HAVING / GROUP BY

In addition to the simple expressions that we introduced last lesson, SQL also supports the use of aggregate expressions (or functions) that allow you to summarize information about a group of rows of data.

```sql
# Select query with aggregate functions over all rows
SELECT AGG_FUNC(column_or_expression) AS aggregate_description, â€¦
FROM mytable
WHERE constraint_expression;
```

| Function                                                     | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| **COUNT(*****)**, **COUNT(***column***)**                    | A common function used to counts the number of rows in the group if no column name is specified. Otherwise, count the number of rows in the group with non-NULL values in the specified column. |
| **MIN(***column***)**                                        | Finds the smallest numerical value in the specified column for all rows in the group. |
| **MAX(***column***)**                                        | Finds the largest numerical value in the specified column for all rows in the group. |
| **AVG(***column*)                                            | Finds the average numerical value in the specified column for all rows in the group. |
| **SUM(***column***)**                                        | Finds the sum of all numerical values in the specified column for the rows in the group. |
| Docs: [MySQL](https://dev.mysql.com/doc/refman/5.6/en/group-by-functions.html), [Postgres](http://www.postgresql.org/docs/9.4/static/functions-aggregate.html), [SQLite](http://www.sqlite.org/lang_aggfunc.html), [Microsoft SQL Server](https://msdn.microsoft.com/en-us/library/ms173454.aspx) |                                                              |

```sql
# Select query with aggregate functions over groups
SELECT AGG_FUNC(column_or_expression) AS aggregate_description, â€¦
FROM mytable
WHERE constraint_expression
GROUP BY column;

# sample
SELECT department, AVG(salary) AS avg_salary
FROM employees
GROUP BY department;
```

The `GROUP BY` clause works by grouping rows that have the same value in the column specified.

**ä¸èƒ½åœ¨ `WHERE` é‡Œç›´æ¥ç”¨ `MAX()`**

èšåˆå‡½æ•°è¦ä¹ˆç”¨åœ¨ `SELECT`ã€`HAVING`ï¼Œè¦ä¹ˆç”¨å­æŸ¥è¯¢

```sql
SELECT *
FROM employees
WHERE years_employed = (
    SELECT MAX(years_employed) FROM employees
);

SELECT *
FROM employees
ORDER BY years_employed DESC
LIMIT 1;
```

Luckily, SQL allows us to do this by adding an additional `HAVING` clause which is used specifically with the `GROUP BY` clause to allow us to filter grouped rows from the result set.

```sql
# Select query with HAVING constraint
SELECT group_by_column, AGG_FUNC(column_expression) AS aggregate_result_alias, â€¦
FROM mytable
WHERE condition
GROUP BY column
HAVING group_condition;
```

```sql
SELECT role, COUNT(role) AS total
FROM employees
WHERE role IN ('Artist')
GROUP BY role

SELECT role, SUM(years_employed) AS total
FROM employees
GROUP BY role
HAVING role IN ('Engineer')
```

```sql
# Complete SELECT query
SELECT DISTINCT column, AGG_FUNC(column_or_expression), â€¦
FROM mytable
    JOIN another_table
      ON mytable.column = another_table.column
    WHERE constraint_expression
    GROUP BY column
    HAVING constraint_expression
    ORDER BY column ASC/DESC
    LIMIT count OFFSET COUNT;
```

```sql
# Find the total domestic and international sales that can be attributed to each director

SELECT 
    movies.director,
    SUM(boxoffice.domestic_sales) AS total_domestic_sales,
    SUM(boxoffice.international_sales) AS total_international_sales,
    SUM(boxoffice.domestic_sales + boxoffice.international_sales) AS total_sales
FROM movies
INNER JOIN boxoffice
ON movies.id = boxoffice.movie_id
GROUP BY movies.director;

```

## 9. INSERT INTO

In SQL, the *database schema* is what describes the structure of each table, and the datatypes that each column of the table can contain.

```sql
# Insert statement with specific columns
INSERT INTO mytable
(column, another_column, â€¦)
VALUES (value_or_expr, another_value_or_expr, â€¦),
      (value_or_expr_2, another_value_or_expr_2, â€¦)
  
# Insert statement with values for all columns
INSERT INTO mytable
VALUES (value_or_expr, another_value_or_expr, â€¦),
       (value_or_expr_2, another_value_or_expr_2, â€¦)
       
# sample
INSERT INTO boxoffice
(movie_id, rating, sales_in_millions)
VALUES (1, 9.9, 283742034 / 1000000);
```

## 10. UPDATE

```sql
# Update statement with values
UPDATE mytable
SET column = value_or_expr, 
    other_column = another_value_or_expr, 
    â€¦
WHERE condition;
```

```sql
UPDATE employees
SET salary = salary + 500
WHERE name = 'Bob';
```

âš ï¸ Most people working with SQL **will** make mistakes updating data at one point or another. Whether it's updating the wrong set of rows in a production database, or accidentally leaving out the `WHERE` clause (which causes the update to apply to *all* rows), you need to be extra careful when constructing `UPDATE` statements.

One helpful tip is to always write the constraint first and test it in a `SELECT` query to make sure you are updating the right rows, and only then writing the column/value pairs to update.

## 11. DELETE

```sql
# Delete statement with condition
DELETE FROM mytable
WHERE condition;
```

## 12. CREATE

```sql
# Create table statement w/ optional table constraint and default value
CREATE TABLE IF NOT EXISTS mytable (
    column DataType TableConstraint DEFAULT default_value,
    another_column DataType TableConstraint DEFAULT default_value,
    â€¦
);
```

```sql
# Movies table schema
CREATE TABLE movies (
    id INTEGER PRIMARY KEY,
    title TEXT,
    director TEXT,
    year INTEGER, 
    length_minutes INTEGER # æœ€åä¸èƒ½æœ‰é€—å·...
);
```



| Data type                                                    | Description                                                  |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| `INTEGER`, `BOOLEAN`                                         | The integer datatypes can store whole integer values like the count of a number or an age. In some implementations, the boolean value is just represented as an integer value of just 0 or 1. |
| `FLOAT`, `DOUBLE`, `REAL`                                    | The floating point datatypes can store more precise numerical data like measurements or fractional values. Different types can be used depending on the floating point precision required for that value. |
| `CHARACTER(num_chars)`, `VARCHAR(num_chars)`, `TEXT`         | The text based datatypes can store strings and text in all sorts of locales. The distinction between the various types generally amount to underlaying efficiency of the database when working with these columns.Both the CHARACTER and VARCHAR (variable character) types are specified with the max number of characters that they can store (longer values may be truncated), so can be more efficient to store and query with big tables. |
| `DATE`, `DATETIME`                                           | SQL can also store date and time stamps to keep track of time series and event data. They can be tricky to work with especially when manipulating data across timezones. |
| `BLOB`                                                       | Finally, SQL can store binary data in blobs right in the database. These values are often opaque to the database, so you usually have to store them with the right metadata to requery them. |
| Docs: [MySQL](http://dev.mysql.com/doc/refman/5.6/en/data-types.html), [Postgres](http://www.postgresql.org/docs/9.4/static/datatype.html), [SQLite](https://www.sqlite.org/datatype3.html), [Microsoft SQL Server](https://msdn.microsoft.com/en-us/library/ms187752.aspx) |                                                              |

### Table constraints

We aren't going to dive too deep into table constraints in this lesson, but each column can have additional table constraints on it which limit what values can be inserted into that column. This is not a comprehensive list, but will show a few common constraints that you might find useful.

| Constraint           | Description                                                  |
| -------------------- | ------------------------------------------------------------ |
| `PRIMARY KEY`        | This means that the values in this column are unique, and each value can be used to identify a single row in this table. |
| `AUTOINCREMENT`      | For integer values, this means that the value is automatically filled in and incremented with each row insertion. Not supported in all databases. |
| `UNIQUE`             | This means that the values in this column have to be unique, so you can't insert another row with the same value in this column as another row in the table. Differs from the `PRIMARY KEY` in that it doesn't have to be a key for a row in the table. |
| `NOT NULL`           | This means that the inserted value can not be `NULL`.        |
| `CHECK (expression)` | This allows you to run a more complex expression to test whether the values inserted are valid. For example, you can check that values are positive, or greater than a specific size, or start with a certain prefix, etc. |
| `FOREIGN KEY`        | This is a consistency check which ensures that each value in this column corresponds to another value in a column in another table.  For example, if there are two tables, one listing all Employees by ID, and another listing their payroll information, the `FOREIGN KEY` can ensure that every row in the payroll table corresponds to a valid employee in the master Employee list. |

## 13. ALTER

```sql
# Altering table to add new column(s)
ALTER TABLE mytable
ADD column DataType OptionalTableConstraint 
    DEFAULT default_value;
    
# Altering table to remove column(s)
ALTER TABLE mytable
DROP column_to_be_deleted;

# Altering table name
ALTER TABLE mytable
RENAME TO new_table_name;

ALTER TABLE movies
ADD COLUMN Language TEXT
DEFAULT 'English'
```

## 14. DROP

```sql
# Drop table statement
DROP TABLE IF EXISTS mytable;
```

# Document databases

The schema of the database exists only in the program code, which interprets the data in a specific way, e.g. by identifying that some of the fields are references to objects in another collection.

MongoDB also does not care what fields the entities stored in the collections have. Therefore MongoDB leaves it entirely up to the programmer to ensure that the correct information is being stored in the database.

One of the advantages is the flexibility that schema agnosticism brings: since the schema does not need to be defined at the database level, application development may be faster in certain cases, and easier, with less effort needed in defining and modifying the schema in any case. 

Problems with not having a schema are related to error-proneness: everything is left up to the programmer. The database itself has no way of checking whether the data in it is *honest*,

The reason why the the previous sections of the course used MongoDB is precisely because of its schema-less nature, which has made it easier to use the database for someone with little knowledge of relational databases. For most of the use cases of this course, I personally would have chosen to use a relational database.

# Application database

 There are many options, but we will be using the currently most popular Open Source solution [PostgreSQL](https://www.postgresql.org/). 

Note that if you only need the database, and are not planning to deploy the app to Fly.io, it is also possible to [just create the database to Fly.io](https://fly.io/docs/mpg/).or render https://render.com/docs/postgresql

åŸºæœ¬éƒ½åœ¨æ”¶è´¹ï¼Œrenderæœ‰ä¸€ä¸ª30å¤©çš„å…è´¹è¯•ç”¨ï¼Œç”¨æ¥ç»ƒæ‰‹æˆ‘çœ‹æ˜¯å¯ä»¥çš„

1. åœ¨fly.io/otherså’Œherokuåˆ›å»ºPostgresäº‘æ•°æ®åº“ / æˆ–è€…å°è¯•æœ¬åœ°æ„å»ºæ•°æ®åº“ï¼Œé€šè¿‡docker è·‘æœåŠ¡
2. ç”¨ [sequelize](https://sequelize.org/master/)ä¸­é—´ä»¶ä½¿ç”¨æ•°æ®åº“

# docker with Postgres Image

Start Postgres [Docker image](https://hub.docker.com/_/postgres) with the command

```bash
# build postgres database in docker
# option 1
docker run --name some-postgres -e POSTGRES_PASSWORD=mysecretpassword -d postgres
# option 2
docker run -e POSTGRES_PASSWORD=mysecretpassword -p 5432:5432 postgres
# option 3 (prefer)
docker run --name hello-postgres -e POSTGRES_PASSWORD=mysecretpassword -p 5432:5432 -d postgres

# èµ°bash command æ“ä½œæ•°æ®åº“ command 4
docker exec -it hello-postgres psql -U postgres postgres
# Defined in this way, the data stored in the database is persisted only as long as the container exists. 
```

`--name some-postgres`ï¼šç»™å®¹å™¨èµ·åå« `some-postgres`ï¼Œæ–¹ä¾¿åç»­é€šè¿‡åå­—ç®¡ç†ï¼ˆä¾‹å¦‚ `docker stop some-postgres`ã€`docker exec -it some-postgres bash`ï¼‰ã€‚

`-e POSTGRES_PASSWORD=mysecretpassword`ï¼šè®¾ç½® PostgreSQL çš„ç®¡ç†å‘˜å¯†ç ã€‚

`-d`ï¼šåå°è¿è¡Œï¼ˆdetached modeï¼‰ã€‚

`postgres`ï¼šé•œåƒåã€‚

**ç‰¹ç‚¹ï¼š**

- å®¹å™¨ä¼šè‡ªåŠ¨åœ¨å†…éƒ¨å¼€æ”¾ PostgreSQL é»˜è®¤ç«¯å£ï¼ˆ5432ï¼‰ï¼Œä½†**æ²¡æœ‰æ˜ å°„åˆ°å®¿ä¸»æœº**ã€‚
- å› æ­¤ï¼Œä½ ä¸èƒ½ç›´æ¥åœ¨å®¿ä¸»æœºé€šè¿‡ `localhost:5432` è®¿é—®æ•°æ®åº“ã€‚
- é€‚åˆå®¹å™¨é—´é€šä¿¡ï¼ˆæ¯”å¦‚å¦ä¸€ä¸ªå®¹å™¨è¿æ¥åˆ°å®ƒï¼‰ã€‚

Command 2æ²¡æœ‰ `--name`ï¼ŒDocker ä¼šè‡ªåŠ¨åˆ†é…ä¸€ä¸ªéšæœºå®¹å™¨åã€‚

`-e POSTGRES_PASSWORD=mysecretpassword`ï¼šåŒæ ·è®¾ç½®å¯†ç ã€‚

`-p 5432:5432`ï¼šå°†å®¹å™¨å†…çš„ 5432 ç«¯å£æ˜ å°„åˆ°å®¿ä¸»æœºçš„ 5432 ç«¯å£ã€‚

æ²¡æœ‰ `-d`ï¼Œæ‰€ä»¥å®ƒä¼š**å‰å°è¿è¡Œ**ï¼ˆé™¤éä½ åŠ ä¸Š `-d`ï¼‰ã€‚

**ç‰¹ç‚¹ï¼š**

- å¯ä»¥åœ¨å®¿ä¸»æœºä¸Šç›´æ¥ç”¨å‘½ä»¤è¿æ¥æ•°æ®åº“ï¼š

  ```bash
  psql -h localhost -U postgres
  ```

- æ¯æ¬¡é‡å¯å®¹å™¨ååç§°å¯èƒ½ä¸åŒï¼ˆä¸æ–¹ä¾¿ç®¡ç†ï¼‰ã€‚

`docker exec -it hello-postgres psql -U postgres postgres`

| éƒ¨åˆ†             | ä½œç”¨                                                         |
| ---------------- | ------------------------------------------------------------ |
| `docker exec`    | åœ¨**å·²è¿è¡Œçš„å®¹å™¨**é‡Œæ‰§è¡Œä¸€ä¸ªå‘½ä»¤ã€‚                           |
| `-it`            | ç»„åˆä¸¤ä¸ªå‚æ•°ï¼š - `-i` = äº¤äº’æ¨¡å¼ (interactive) - `-t` = åˆ†é…ä¸€ä¸ªä¼ªç»ˆç«¯ (tty)ï¼Œè®©ä½ èƒ½è¾“å…¥å‘½ä»¤ã€‚ |
| `hello-postgres` | è¿™æ˜¯ä½ è¦è¿›å…¥çš„å®¹å™¨åï¼ˆæ¯”å¦‚ç”¨ `docker ps` èƒ½çœ‹åˆ°çš„ `NAMES` åˆ—ï¼‰ã€‚ |
| `psql`           | PostgreSQL è‡ªå¸¦çš„å‘½ä»¤è¡Œå®¢æˆ·ç«¯ï¼Œç”¨æ¥å’Œæ•°æ®åº“äº¤äº’ã€‚            |
| `-U postgres`    | æŒ‡å®šè¿æ¥æ•°æ®åº“çš„ç”¨æˆ·ï¼ˆè¿™é‡Œæ˜¯é»˜è®¤ç®¡ç†å‘˜ç”¨æˆ· `postgres`ï¼‰ã€‚    |
| `postgres`       | æœ€åè¿™ä¸ªæ˜¯**è¦è¿æ¥çš„æ•°æ®åº“å**ï¼ˆé€šå¸¸é»˜è®¤æ•°æ®åº“ä¹Ÿå« `postgres`ï¼‰ã€‚ |

-----

æœ‰å¾ˆå¤šæ“ä½œPostgres çš„å¯è§†åŒ–å·¥å…·ï¼Œä¹Ÿå¯ä»¥èµ°å‘½ä»¤ã€‚

There are many ways to do this, there are several different graphical user interfaces, such as [pgAdmin](https://www.pgadmin.org/). However, we will be using Postgres [psql](https://www.postgresql.org/docs/current/app-psql.html) command-line tool.

```bash
\d # which tells you the contents of the database:
```

åœ¨å‘½ä»¤é‡Œå°±å¯ä»¥èµ°Sqlè¯­æ³•æ¥å¢åˆ æ”¹æŸ¥æ•°æ®åº“äº†ã€‚

## Connecting to a Database build in docker

Usage: https://www.postgresql.org/docs/current/app-psql.html

install devs

```bash
npm install express dotenv pg sequelize
```

 [sequelize](https://sequelize.org/master/) is the library through which we use Postgres. 

https://sequelize.org/docs/v6/core-concepts/assocs/#one-to-many-relationships

ç”¨è¿™ä¸ªä¸­é—´ä»¶æ“ä½œ/é“¾æ¥æ•°æ®åº“

```bash
docker run --name hello-postgres -e POSTGRES_PASSWORD=mysecretpassword -p 5432:5432 -d postgres

DATABASE_URL=postgresql://postgres:mysecretpassword@localhost:5432/postgres

# entry bash and into cli
docker exec -it hello-postgres bash
psql -U postgres

# è¿›å…¥æ•°æ®åº“ CLI
docker exec -it hello-postgres psql -U postgres
```

```sql
# blogs table schema
CREATE TABLE blogs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    author TEXT,
    url TEXT NOT NULL,
    title TEXT NOT NULL, 
    likes INTEGER DEFAULT 0
);

INSERT INTO blogs
(id, author, url, title)
VALUES (1, 'chen ruo', 'https://dashboard.heroku.com/', 'book2');

curl -X GET http://localhost:3001/api/users
curl -X GET http://localhost:3001/api/blogs

curl -X POST http://localhost:3001/api/blogs \
  -H "Content-Type: application/json" \
  -d '{"author":"Alice","title":"New Blog","url":"https://example.com"}'

curl -X DELETE http://localhost:3001/api/blogs/4

curl -X PUT http://localhost:3001/api/blogs/9 \
  -H "Content-Type: application/json" \
  -d '{"author":"Butan","title":"New Blog4","url":"https://example.com", "likes": 19}'
  
curl -X POST http://localhost:3001/api/users \
  -H "Content-Type: application/json" \
  -d '{"username": "Alice", "name": "Alice-name", "email": "xusumu@gmail.com"}'
  
curl -X POST http://localhost:3001/api/users \
-H "Content-Type: application/json" \
-d '{"username": "Alice2", "name": "Alice-name2", "email": "xusumu@gmail.com"}'
  
curl -X POST http://localhost:3001/api/login \
  -H "Content-Type: application/json" \
  -d '{"username": "Alice", "name": "Alice-name", "password": "secret"}'
  
  curl -X POST http://localhost:3001/api/login \
  -H "Content-Type: application/json" \
  -d '{"username": "Bob", "name": "Bob-name", "password": "secret"}'
  
curl -X POST http://localhost:3001/api/blogs \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJBbGljZSIsImlhdCI6MTc2MTkxMDc4MCwiZXhwIjoxNzYyNTE1NTgwfQ.Gqq9CGDfH_4p-rXPFWvLcIlQOkDru9EjI6vstnWySN0" \
  -d '{"author":"XXXX3","title":"New Blog react3","url":"https://example.com", "year": 1996}'

curl -X DELETE http://localhost:3001/api/blogs/5 \
  -H "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6IkFsaWNlIiwiaWQiOjEsImlhdCI6MTc2MTg4OTA4NX0.-0Gd3LVWWXlom3PbqdjqR_Z4qAEKoKrTbGavKZPYxy8"
  
curl -X DELETE http://localhost:3001/api/logout \
  -H "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJBbGljZSIsImlhdCI6MTc2MTkxMDc4MCwiZXhwIjoxNzYyNTE1NTgwfQ.Gqq9CGDfH_4p-rXPFWvLcIlQOkDru9EjI6vstnWySN0"
  
INSERT INTO user_marks (user_id, blog_id) values (1, 1);

curl -X PUT http://localhost:3001/api/readinglist/1 \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6IkFsaWNlIiwiaWQiOjEsImlhdCI6MTc2MTkwMDI5NX0.jPlSRr88ttUz8mUY9W505w6BlhBfdi7meDLJpDFBdMY" \
  -d '{"read": true}'

```

 `express-async-errors` æ˜¯ä¸€ä¸ª **å¤„ç† Express å¼‚æ­¥è·¯ç”±é”™è¯¯çš„åº“**ï¼Œç›®çš„æ˜¯è®©ä½  **ä¸ç”¨æ¯ä¸ª async è·¯ç”±é‡Œéƒ½å†™ try/catch**ï¼Œä»ç„¶å¯ä»¥è®©é”™è¯¯ä¼ åˆ°å…¨å±€é”™è¯¯å¤„ç†ä¸­é—´ä»¶ã€‚

#### ä¸ç”¨ `express-async-errors`ï¼Œç›´æ¥å…¨å±€ try/catch

- Express 5 æœ¬èº« **å·²ç»æ”¹è¿›äº† async é”™è¯¯å¤„ç†**
- æ‰€ä»¥ä½  **å¯ä»¥ç›´æ¥å†™ async è·¯ç”±**ï¼ŒæŠ›å‡ºçš„å¼‚å¸¸ä¼šè¢« Express 5 è‡ªåŠ¨ä¼ åˆ°é”™è¯¯å¤„ç†ä¸­é—´ä»¶

```js
// å…¨å±€é”™è¯¯å¤„ç†ä¸­é—´ä»¶
app.use((err, req, res, next) => {
  console.error(err)
  res.status(500).json({ error: err.message })
})
```

```js
router.get("/", async (req, res) => {
  const users = await User.findAll({
    
    // Making a join query
    include: {
      model: Blog,
    },
  });
  res.json(users);
});
```

```sql
SELECT "User". "id", "User". "username", "User". "name", "Notes". "id" AS "Notes.id", "Notes". "content" AS "Notes.content", "Notes". "important" AS "Notes.important", "Notes". "date" AS "Notes.date", "Notes". "user_id" AS "Notes.UserId"
FROM "users" AS "User" LEFT OUTER JOIN "notes" AS "Notes" ON "User". "id" = "Notes". "user_id";
```

```js
const user = await User.findByPk(req.decodedToken.id)

// create a note without saving it yet
const note = Note.build({ ...req.body, date: new Date() })
 // put the user id in the userId property of the created note
note.userId = user.id
// store the note object in the database
await note.save()
```

# migrations

[migrations](https://sequelize.org/master/manual/migrations.html)

a migration is a single JavaScript file that describes some modification to a database. 

ä¸€ä¸ª **migrationï¼ˆè¿ç§»ï¼‰** å°±æ˜¯ä¸€ä¸ª **JavaScript æ–‡ä»¶**ï¼Œé‡Œé¢å†™ç€å¯¹æ•°æ®åº“çš„ä¸€æ¬¡ä¿®æ”¹ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™ä¸ªæ–‡ä»¶æè¿°äº†æ•°æ®åº“ç»“æ„è¦æ€ä¹ˆâ€œå˜â€ã€‚æ¯æ¬¡ä½ å¯¹æ•°æ®åº“ç»“æ„æœ‰å˜åŠ¨ï¼ˆä¸ç®¡æ˜¯ä¸€é¡¹è¿˜æ˜¯å¤šé¡¹ï¼‰ï¼Œä½ éƒ½åº”è¯¥æ–°å»ºä¸€ä¸ª **ç‹¬ç«‹çš„ migration æ–‡ä»¶**ã€‚å®ƒåœ¨æ•°æ®åº“é‡Œæœ‰ä¸€å¼ ä¸“é—¨çš„è¡¨ï¼ˆé€šå¸¸å« `SequelizeMeta`ï¼‰ï¼Œå­˜æ”¾æ‰§è¡Œè¿‡çš„ migration æ–‡ä»¶åã€‚è¿™æ ·ä¸€æ¥ï¼šæ•°æ®åº“çš„å˜åŒ–æ˜¯**å¯æ§çš„ã€æœ‰è®°å½•çš„**ï¼›æ¯ä¸ªæ”¹åŠ¨éƒ½æœ‰ç›¸åº”çš„ JS æ–‡ä»¶ï¼›è¿™äº›æ–‡ä»¶å¯ä»¥æ”¾è¿› **ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼ˆå¦‚ Gitï¼‰**ï¼Œæ–¹ä¾¿å›¢é˜Ÿåä½œå’Œå›æº¯ã€‚

![image-20251111213244036](https://s2.loli.net/2025/11/11/p53ERXoSmYOeGyP.png)

We could run the migrations from the command line using the [Sequelize command line tool](https://github.com/sequelize/cli). However, we choose to perform the migrations manually from the program code using the [Umzug](https://github.com/sequelize/umzug) library. Let's install the library

When defining migrations, it is essential to remember that unlike models, column and table names are written in snake case form:

```js
const { DataTypes } = require('sequelize')

module.exports = {
  up: async ({ context: queryInterface }) => {
    await queryInterface.createTable('notes', {
      id: {
        type: DataTypes.INTEGER,
        primaryKey: true,
        autoIncrement: true
      },
      content: {
        type: DataTypes.TEXT,
        allowNull: false
      },
      important: {
        type: DataTypes.BOOLEAN,
        allowNull: false
      },
      date: {
        type: DataTypes.DATE
      },
    })
    await queryInterface.createTable('users', {
      id: {
        type: DataTypes.INTEGER,
        primaryKey: true,
        autoIncrement: true
      },
      username: {
        type: DataTypes.STRING,
        unique: true,
        allowNull: false
      },
      name: {
        type: DataTypes.STRING,
        allowNull: false
      },
    })
    await queryInterface.addColumn('notes', 'user_id', {
      type: DataTypes.INTEGER,
      allowNull: false,
      references: { model: 'users', key: 'id' },
    })
  },
  down: async ({ context: queryInterface }) => {
    await queryInterface.dropTable('notes')
    await queryInterface.dropTable('users')
  },
}
```

So in migrations, the names of the tables and columns are written exactly as they appear in the database, while models use Sequelize's default camelCase naming convention.ï¼ˆemmmmä¾‹å­é‡Œé¢ä¸æ˜¯ä¸‹åˆ’çº¿å—ã€‚ã€‚ã€‚

```
ğŸ‘€ Migrations up to date { files: [] }
```

ä¼šå‡ºç°æ–‡ä»¶ç©ºæ•°ç»„çš„æƒ…å†µï¼Œæ˜¯å› ä¸ºåªæ‰§è¡Œæ–°çš„è¿ç§»ï¼ˆæœªæ‰§è¡Œè¿‡çš„æ–‡ä»¶ï¼‰ã€‚å»æŸ¥çœ‹SELECT * FROM migrations;çš„å†…å®¹çš„æ—¶å€™ï¼Œä¼šçœ‹åˆ°è¡¨è¾“å‡ºï¼Œè¯´æ˜è¡¨å•æ‰§è¡Œè¿‡äº†ã€‚

## é‡æ–°è¿è¡Œè¿ç§»ï¼ˆæ¯”å¦‚ä¿®æ”¹äº† migration æ–‡ä»¶ï¼‰

dockeré‡Œçš„æ‰€æœ‰ç›¸å…³è¡¨æ ¼éœ€è¦å…¨éƒ¨åˆ é™¤

æ–¹å¼ 1ï¼šæ’¤é”€æ‰€æœ‰è¿ç§»å†é‡è·‘

```js
npx sequelize-cli db:migrate:undo:all
npx sequelize-cli db:migrate

// æˆ–å¦‚æœä½ ç”¨çš„æ˜¯ Umzug è‡ªå·±å†™çš„
await migrator.down({ to: 0 }); // å›æ»šæ‰€æœ‰
await migrator.up(); // é‡æ–°æ‰§è¡Œæ‰€æœ‰è¿ç§»
```

æ–¹å¼ 2ï¼šæ‰‹åŠ¨æ¸…ç©º migrations è¡¨

```sql
DELETE FROM migrations;

npm run migrate
```

ä¸€å®šè¦åˆ é™¤ migrations è¡¨ï¼

## æ ¼å¼åŒ–æ•°æ®åº“


## æ–¹æ³• 1ï¼šåœ¨ **psql** é‡Œç”¨ SQL

æ‰“å¼€ `psql` è¿æ¥åˆ°ä½ çš„æ•°æ®åº“ï¼š

```
psql -U postgres -d postxxx
```

ç„¶åæ‰§è¡Œï¼š

```
DROP SCHEMA public CASCADE;
CREATE SCHEMA public;
```

**è¯´æ˜ï¼š**

- `DROP SCHEMA public CASCADE;` ä¼šåˆ é™¤ public schema ä¸‹çš„æ‰€æœ‰è¡¨ã€åºåˆ—ã€çº¦æŸç­‰ã€‚
- `CREATE SCHEMA public;` é‡å»º schemaï¼Œè¿™æ ·æ•°æ®åº“å°±ç©ºäº†ï¼Œå¯ä»¥é‡æ–°å»ºè¡¨ã€‚
- éå¸¸é€‚åˆå¿«é€Ÿé‡ç½®æ•°æ®åº“ã€‚

# token å¤±æ•ˆ

Keep in mind that actions requiring login should not be successful with an "expired token", i.e. with the same token after logging out. You may also choose to use some purpose-built npm library to handle sessions.

## ğŸ§© ç¬¬ä¸€éƒ¨åˆ†ï¼šè§£é‡Šè¿™å¥è¯çš„æ„æ€

> â€œKeep in mind that actions requiring login should not be successful with an â€˜expired tokenâ€™, i.e. with the same token after logging out.â€

æ„æ€æ˜¯ï¼š

> å½“ç”¨æˆ· **ç™»å‡º(logout)** ä¹‹åï¼Œå³ä½¿ä»–ä»ç„¶ä¿ç•™äº†åŸæ¥çš„ **JWT token**ï¼Œ
>  ä¹Ÿ **ä¸åº”è¯¥å†èƒ½è°ƒç”¨ä»»ä½•éœ€è¦ç™»å½•æƒé™çš„æ¥å£**ã€‚

æ¢å¥è¯è¯´ï¼š

- ä½ ä¸èƒ½åªè®©å‰ç«¯â€œå¿˜æ‰ tokenâ€å°±å®Œäº‹ã€‚
- è¿˜éœ€è¦åœ¨æœåŠ¡ç«¯ **è®©è¿™ä¸ª token æ— æ•ˆåŒ–ï¼ˆblacklist/åˆ é™¤ï¼‰**ã€‚
- å¦åˆ™ï¼Œåˆ«äººç”¨ç›¸åŒ token ä¾ç„¶å¯ä»¥è®¿é—®å—ä¿æŠ¤çš„èµ„æºï¼Œ**ä¸å®‰å…¨**ã€‚

------

## ğŸ” è§£å†³æ–¹æ¡ˆæ€è·¯

ç™»å‡ºå token è‡ªåŠ¨å¤±æ•ˆæœ‰ä¸¤ç§å¸¸è§å®ç°æ–¹å¼ï¼š

| æ–¹å¼                       | æ€è·¯                                                         | ä¼˜ç‚¹       | ç¼ºç‚¹                                  |
| -------------------------- | ------------------------------------------------------------ | ---------- | ------------------------------------- |
| âœ… **å­˜å‚¨ tokenï¼ˆé»‘åå•ï¼‰** | æŠŠç™»å½•ç”Ÿæˆçš„ token å­˜åœ¨æ•°æ®åº“ä¸­ï¼ˆå¦‚ `UserToken` è¡¨ï¼‰ã€‚ç™»å‡ºæ—¶åˆ é™¤ã€‚éªŒè¯æ—¶å…ˆæŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨ã€‚ | å®‰å…¨ã€ç®€å• | æ¯æ¬¡éªŒè¯éƒ½è¦æŸ¥æ•°æ®åº“                  |
| â±ï¸ **è®¾ç½®è¿‡æœŸæ—¶é—´ (exp)**   | token é‡Œå†™å…¥ `exp` æ—¶é—´ï¼Œæ¯”å¦‚ 1 å°æ—¶åè‡ªåŠ¨è¿‡æœŸã€‚             | æ— éœ€æ•°æ®åº“ | ç™»å‡ºå‰ token ä»ç„¶æœ‰æ•ˆï¼ˆä¸èƒ½ç«‹åˆ»å¤±æ•ˆï¼‰ |

ğŸ‘‰ æ‰€ä»¥æœ€å®‰å…¨çš„åšæ³•æ˜¯ï¼š
 **ä¸¤è€…ç»“åˆï¼š**
 JWT å†…ç½®è¿‡æœŸæ—¶é—´ï¼ˆæ¯”å¦‚ 1 å°æ—¶ï¼‰ï¼Œ
 åŒæ—¶åœ¨æœåŠ¡ç«¯ç»´æŠ¤ä¸€ä»½æœ‰æ•ˆ token è¡¨ã€‚ç™»å‡ºæ—¶ä»è¡¨ä¸­åˆ æ‰ã€‚

------

## âš™ï¸ ç¬¬äºŒéƒ¨åˆ†ï¼šæ¨èçš„ npm åº“

ä½ æœ‰ä¸¤ç§è·¯çº¿å¯ä»¥é€‰ ğŸ‘‡

### ğŸ§© è·¯çº¿ A â€” ç»§ç»­ç”¨ JWTï¼ˆä½ ç°åœ¨çš„æ–¹æ¡ˆï¼‰

ä¿æŒ `jsonwebtoken`ï¼Œä½†é…åˆ â€œtoken è¡¨ + éªŒè¯é€»è¾‘â€ï¼š

```bash
npm install jsonwebtoken
```

åŠ ä¸€ä¸ª token æ ¡éªŒä¸­é—´ä»¶ï¼Œæ¯”å¦‚ï¼š

```js
import jwt from "jsonwebtoken";
import { UserToken } from "../models/index.js";

export const authenticateToken = async (req, res, next) => {
  const authorization = req.get("authorization");
  if (!authorization?.toLowerCase().startsWith("bearer ")) {
    return res.status(401).json({ error: "token missing" });
  }

  const token = authorization.substring(7);

  try {
    const decoded = jwt.verify(token, process.env.SECRET);

    // ğŸ§  æ£€æŸ¥ token æ˜¯å¦ä»åœ¨æ•°æ®åº“ä¸­ï¼ˆé˜²æ­¢ç™»å‡ºåç»§ç»­ä½¿ç”¨ï¼‰
    const validToken = await UserToken.findOne({ where: { userId: decoded.id, token } });
    if (!validToken) {
      return res.status(401).json({ error: "token expired or invalid" });
    }

    req.decodedToken = decoded;
    next();
  } catch (err) {
    return res.status(401).json({ error: "token invalid" });
  }
};
```

è¿™æ ·ï¼Œç™»å‡ºååˆ é™¤ token å°±å®Œå…¨å®‰å…¨äº† âœ…ã€‚

------

### ğŸª„ è·¯çº¿ B â€” ä½¿ç”¨ session ç®¡ç†åº“

å¦‚æœä½ ä¸æƒ³è‡ªå·±ç»´æŠ¤ token è¡¨ï¼Œå¯ä»¥æ”¹ç”¨ **session ç®¡ç†åº“**ï¼Œè®©å®ƒè‡ªåŠ¨å¤„ç†ç™»å½•çŠ¶æ€å’Œè¿‡æœŸé—®é¢˜ã€‚

#### å¸¸ç”¨æ¨èï¼š

| åº“å                  | ç®€ä»‹                                                         | é€‚åˆåœºæ™¯           |
| --------------------- | ------------------------------------------------------------ | ------------------ |
| **express-session**   | Express å®˜æ–¹æ¨èçš„ session ä¸­é—´ä»¶ï¼Œç”¨ cookie+server å­˜å‚¨ session | æ™®é€š Web åº”ç”¨      |
| **connect-pg-simple** | æŠŠ express-session å­˜åœ¨ PostgreSQL é‡Œ                        | ä½ å½“å‰çš„æ•°æ®åº“åœºæ™¯ |
| **passport.js**       | ä¸€æ•´å¥—è®¤è¯æ¡†æ¶ï¼Œæ”¯æŒæœ¬åœ°ç™»å½•ã€JWTã€OAuth ç­‰å¤šç§ç­–ç•¥          | å¤§å‹é¡¹ç›®           |
| **iron-session**      | æ— éœ€æ•°æ®åº“ï¼Œsession åŠ å¯†å­˜åœ¨ cookie ä¸­                       | Next.js/ç®€å•åç«¯   |

------

ğŸ’¡ ç®€å•æ¨èï¼š
 å¦‚æœä½ å·²ç»ç”¨ PostgreSQLï¼Œå¯ä»¥ç›´æ¥ï¼š

```bash
npm install express-session connect-pg-simple
```

ç„¶ååœ¨ `app.js` ä¸­ï¼š

```js
import session from "express-session";
import connectPgSimple from "connect-pg-simple";
const PgSession = connectPgSimple(session);

app.use(
  session({
    store: new PgSession({ conString: process.env.DATABASE_URL }),
    secret: process.env.SECRET,
    resave: false,
    saveUninitialized: false,
    cookie: { maxAge: 3600 * 1000 } // 1 hour
  })
);
```

è¿™æ · Express ä¼šè‡ªåŠ¨å¸®ä½ ï¼š

- ç™»å½•æ—¶å»ºç«‹ session
- ç™»å‡ºæ—¶é”€æ¯ session
- è¿‡æœŸè‡ªåŠ¨å¤±æ•ˆ
- ä¸ç”¨æ‰‹åŠ¨ç»´æŠ¤ token è¡¨

# UserToken.inité‡Œçš„model nameä¸‹åˆ’çº¿é»˜è®¤æŸ¥è¯¢æ•°æ®åº“çš„åç§°ä¸ºå¤æ•°

Qï¼š æˆ‘çœ‹è¾“å‡ºçš„å‘½ä»¤æ˜¯è¿™ä¸ª    sql: 'SELECT "id", "user_id" AS "userId", "token" FROM "user_tokens" AS "user_token" WHERE "user_token"."user_id" = 1 LIMIT 1;', ä½†æˆ‘æ²¡æœ‰user_tokensçš„ç›¸å…³å‘½ä»¤

###### ChatGPT è¯´ï¼š

éå¸¸å¥½è§‚å¯Ÿ ğŸ‘€ï¼è¿™è¯´æ˜ Sequelize æ­£åœ¨æ‰§è¡Œ

```sql
SELECT ... FROM "user_tokens"
```

ä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒ**æœŸæœ›æ•°æ®åº“é‡Œæœ‰ä¸€å¼ å« `user_tokens` çš„è¡¨**ã€‚

------

### ğŸ” åŸå› 

è¿™æ˜¯ç”±ä½ æ¨¡å‹é‡Œçš„é…ç½®å†³å®šçš„ ğŸ‘‡

```js
UserToken.init(
  {...},
  {
    sequelize,
    underscored: true,
    timestamps: false,
    modelName: "user_token", // âœ… æ³¨æ„è¿™é‡Œï¼
  }
);
```

å½“ä½ åœ¨ `modelName` ä¸­å†™çš„æ˜¯ `"user_token"` å¹¶ä¸”å¯ç”¨äº† `underscored: true`ï¼Œ
 Sequelize ä¼šè‡ªåŠ¨æ¨å¯¼å‡ºè¡¨åæ˜¯ **å¤æ•°å½¢å¼**ï¼Œå³ï¼š

```
user_token â†’ user_tokens
```

> Sequelize é»˜è®¤ä¼šå¯¹ `modelName` è‡ªåŠ¨å¤æ•°åŒ–ä½œä¸ºè¡¨åï¼Œé™¤éä½ æ˜¾å¼æŒ‡å®š `tableName`ã€‚

### âœ… è§£å†³æ–¹æ¡ˆæœ‰ä¸¤ç§

#### âœ… æ–¹æ¡ˆ 1ï¼šä¿æŒé»˜è®¤å¤æ•°åŒ–

ç›´æ¥è®©æ•°æ®åº“çš„è¡¨åæ”¹æˆ `user_tokens` å³å¯ã€‚
 ä¹Ÿå°±æ˜¯åœ¨ migration é‡Œæ”¹æˆï¼š

```js
await queryInterface.createTable("user_tokens", {  // âœ… æ³¨æ„è¿™é‡Œæ”¹æˆå¤æ•°
  id: { type: DataTypes.INTEGER, primaryKey: true, autoIncrement: true },
  user_id: {
    type: DataTypes.INTEGER,
    allowNull: false,
    references: { model: "users", key: "id" },
  },
  token: {
    type: DataTypes.STRING,
    allowNull: false,
  },
});
```

è¿™æ ·æ¨¡å‹å’Œæ•°æ®åº“å°±åŒ¹é…äº†ã€‚

------

#### âœ… æ–¹æ¡ˆ 2ï¼šå¼ºåˆ¶ä½¿ç”¨å•æ•°è¡¨å

å¦‚æœä½ æ›´æƒ³ä¿æŒ `user_token`ï¼ˆå•æ•°ï¼‰ï¼Œå¯ä»¥åŠ ä¸Šï¼š

```js
UserToken.init(
  {...},
  {
    sequelize,
    tableName: "user_token", // âœ… å¼ºåˆ¶æŒ‡å®šè¡¨å
    underscored: true,
    timestamps: false,
    modelName: "UserToken",
  }
);
```

è¿™æ · Sequelize å°±ä¸ä¼šå¤æ•°åŒ–äº†ã€‚
